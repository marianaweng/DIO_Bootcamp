Análise de Sentimentos com Language Studio no Azure AI

Para esse desafio, escolhi a transcrição de fala em texto, e, usando os conhecimentos das aulas organizei 4 áudios de pessoas falando em inglês em diferentes sotaques, sendo um da minha pronuncia para coloca-los no azure speech, assim, foi possível observar a transcrição ocorrendo como representado nas imagens no diretório /images.
Assim, durante a realização desse desafio foi possível observar algumas ocorrências, como, áudios de falas mais lentas e de nativos americanos foram facilmente identificados, enquanto falas com sotaque perdem um pouco em sentido em certos momentos, ainda sim, para os pontos positivos foram as autocorreções que eram visíveis em tempo real, alterando para palavras que condiziam com o sentido e adicionando pontuações (principalmente interrogações).
Ademais, foi possível notar que pausas são assumidas com vírgulas ou pontos finais, além de ele não conseguir identificar palavras que não são da ortografia como no áudio 3 foi falado "DIO" e interpretado como "day your", e, não há indicadores de fala, por exemplo nos audios 1, 2 e 4 há conversas em que mais de uma pessoa fala, e durante a transcrição não há indicadores que uma fala terminou e a de outra pessoa começou.
